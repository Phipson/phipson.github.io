<!DOCTYPE html>
<title>Phipson Lee: Psychology Researcher, Programmer, and Creative</title>
<head>
    <!-- TODO: Compile the CSS File Later -->
    <link rel="stylesheet" type="text/css" href="./../style.css" />
    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    
    <!-- TODO: Update Mobile UIUX -->
    <meta charset="UTF-8">
    <meta property="og:title" content="My Project Portfolio">
    <meta property="og:site_name" content="Phipson Lee: Psychology Researcher, Programmer, and Creative">
    <meta property="og:image" content="img_sources/preview.jpg">
    <meta name="image" content="img_sources/preview.jpg">
    <meta property="og:image:type" content="image/png">
    <meta name="keywords" content="HTML, CSS, Java, SCSS, Javascript, UCLA, Computer Science, Phipson Lee, Lee Cheuk Yin, Portfolio">
    <meta name="author" content="Cheuk Yin Phipson Lee (李卓彥)">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body id="originTop" style="background-color:#FFFFFF; height: 100%" class="animate-in">

  <!-- Main Code for the Side Menu Bar-->
    <div id="SideMenu" class="SideMenuFrame">
      <div id="MenuGrid" class="SideMenuWrapper">
        <div id="IntroWrapper" class="IntroGrid">
          <div id="PortPic" class="PortPic">
            <h4 id="ReturnHomeTitle">&#8592; Back</h4>
          </div>
        </div>

      </div>
    </div>

    <!-- For Scroll 'Swiping' https://stackoverflow.com/questions/31223341/detecting-scroll-direction -->

    <!-- Brief Intro Div About Myself -->

    <!-- Main Code for the Body of the Portfolio -->
    <div id="ARVR-1-Body" class="ProjectBodyFrame">

        <div id="anchor-proj-title" class="SectionHeader">
            <h3>Visual Logic Programming in AR</h3>
        </div>

        <div id="anchor-proj-overview" class="SectionOverview">
            <h4 class="ProjectSectionHeader">Overview</h4>
            <div class="ProjectOverviewBar">
                <div class="OverviewElement">
                    <svg class="overview-icon" viewBox="0 0 20 20">
  <path fill="none" d="M16.254,3.399h-0.695V3.052c0-0.576-0.467-1.042-1.041-1.042c-0.576,0-1.043,0.467-1.043,1.042v0.347H6.526V3.052c0-0.576-0.467-1.042-1.042-1.042S4.441,2.476,4.441,3.052v0.347H3.747c-0.768,0-1.39,0.622-1.39,1.39v11.813c0,0.768,0.622,1.39,1.39,1.39h12.507c0.768,0,1.391-0.622,1.391-1.39V4.789C17.645,4.021,17.021,3.399,16.254,3.399z M14.17,3.052c0-0.192,0.154-0.348,0.348-0.348c0.191,0,0.348,0.156,0.348,0.348v0.347H14.17V3.052z M5.136,3.052c0-0.192,0.156-0.348,0.348-0.348S5.831,2.86,5.831,3.052v0.347H5.136V3.052z M16.949,16.602c0,0.384-0.311,0.694-0.695,0.694H3.747c-0.384,0-0.695-0.311-0.695-0.694V7.568h13.897V16.602z M16.949,6.874H3.052V4.789c0-0.383,0.311-0.695,0.695-0.695h12.507c0.385,0,0.695,0.312,0.695,0.695V6.874z M5.484,11.737c0.576,0,1.042-0.467,1.042-1.042c0-0.576-0.467-1.043-1.042-1.043s-1.042,0.467-1.042,1.043C4.441,11.271,4.908,11.737,5.484,11.737z M5.484,10.348c0.192,0,0.347,0.155,0.347,0.348c0,0.191-0.155,0.348-0.347,0.348s-0.348-0.156-0.348-0.348C5.136,10.503,5.292,10.348,5.484,10.348z M14.518,11.737c0.574,0,1.041-0.467,1.041-1.042c0-0.576-0.467-1.043-1.041-1.043c-0.576,0-1.043,0.467-1.043,1.043C13.475,11.271,13.941,11.737,14.518,11.737z M14.518,10.348c0.191,0,0.348,0.155,0.348,0.348c0,0.191-0.156,0.348-0.348,0.348c-0.193,0-0.348-0.156-0.348-0.348C14.17,10.503,14.324,10.348,14.518,10.348z M14.518,15.212c0.574,0,1.041-0.467,1.041-1.043c0-0.575-0.467-1.042-1.041-1.042c-0.576,0-1.043,0.467-1.043,1.042C13.475,14.745,13.941,15.212,14.518,15.212z M14.518,13.822c0.191,0,0.348,0.155,0.348,0.347c0,0.192-0.156,0.348-0.348,0.348c-0.193,0-0.348-0.155-0.348-0.348C14.17,13.978,14.324,13.822,14.518,13.822z M10,15.212c0.575,0,1.042-0.467,1.042-1.043c0-0.575-0.467-1.042-1.042-1.042c-0.576,0-1.042,0.467-1.042,1.042C8.958,14.745,9.425,15.212,10,15.212z M10,13.822c0.192,0,0.348,0.155,0.348,0.347c0,0.192-0.156,0.348-0.348,0.348s-0.348-0.155-0.348-0.348C9.653,13.978,9.809,13.822,10,13.822z M5.484,15.212c0.576,0,1.042-0.467,1.042-1.043c0-0.575-0.467-1.042-1.042-1.042s-1.042,0.467-1.042,1.042C4.441,14.745,4.908,15.212,5.484,15.212z M5.484,13.822c0.192,0,0.347,0.155,0.347,0.347c0,0.192-0.155,0.348-0.347,0.348s-0.348-0.155-0.348-0.348C5.136,13.978,5.292,13.822,5.484,13.822z M10,11.737c0.575,0,1.042-0.467,1.042-1.042c0-0.576-0.467-1.043-1.042-1.043c-0.576,0-1.042,0.467-1.042,1.043C8.958,11.271,9.425,11.737,10,11.737z M10,10.348c0.192,0,0.348,0.155,0.348,0.348c0,0.191-0.156,0.348-0.348,0.348s-0.348-0.156-0.348-0.348C9.653,10.503,9.809,10.348,10,10.348z"></path>
                      </svg>
                      <div>
                          <h5>Timeline</h5>
                          <br>
                          <p class="overview-text">8 Weeks (2 Months)
                            <br>June 2019 - August 2019
                          </p>
                        </div>
                </div>
                <div class="OverviewElement">
                    <svg class="overview-icon" viewBox="0 0 20 20">
                        <path d="M14.023,12.154c1.514-1.192,2.488-3.038,2.488-5.114c0-3.597-2.914-6.512-6.512-6.512
                          c-3.597,0-6.512,2.916-6.512,6.512c0,2.076,0.975,3.922,2.489,5.114c-2.714,1.385-4.625,4.117-4.836,7.318h1.186
                          c0.229-2.998,2.177-5.512,4.86-6.566c0.853,0.41,1.804,0.646,2.813,0.646c1.01,0,1.961-0.236,2.812-0.646
                          c2.684,1.055,4.633,3.568,4.859,6.566h1.188C18.648,16.271,16.736,13.539,14.023,12.154z M10,12.367
                          c-2.943,0-5.328-2.385-5.328-5.327c0-2.943,2.385-5.328,5.328-5.328c2.943,0,5.328,2.385,5.328,5.328
                          C15.328,9.982,12.943,12.367,10,12.367z"></path>
                      </svg>
                      <div>
                        <h5>Involve members</h5>
                        <br>
                        <p class="overview-text">Phipson (Me)/ Lead
                        </p>
                      </div>
                </div>
                <div class="OverviewElement">
                    <svg class="overview-icon" viewBox="0 0 20 20">
                        <path fill="none" d="M2.25,12.584c-0.713,0-1.292,0.578-1.292,1.291s0.579,1.291,1.292,1.291c0.713,0,1.292-0.578,1.292-1.291S2.963,12.584,2.25,12.584z M2.25,14.307c-0.238,0-0.43-0.193-0.43-0.432s0.192-0.432,0.43-0.432c0.238,0,0.431,0.193,0.431,0.432S2.488,14.307,2.25,14.307z M5.694,6.555H18.61c0.237,0,0.431-0.191,0.431-0.43s-0.193-0.431-0.431-0.431H5.694c-0.238,0-0.43,0.192-0.43,0.431S5.457,6.555,5.694,6.555z M2.25,8.708c-0.713,0-1.292,0.578-1.292,1.291c0,0.715,0.579,1.292,1.292,1.292c0.713,0,1.292-0.577,1.292-1.292C3.542,9.287,2.963,8.708,2.25,8.708z M2.25,10.43c-0.238,0-0.43-0.192-0.43-0.431c0-0.237,0.192-0.43,0.43-0.43c0.238,0,0.431,0.192,0.431,0.43C2.681,10.238,2.488,10.43,2.25,10.43z M18.61,9.57H5.694c-0.238,0-0.43,0.192-0.43,0.43c0,0.238,0.192,0.431,0.43,0.431H18.61c0.237,0,0.431-0.192,0.431-0.431C19.041,9.762,18.848,9.57,18.61,9.57z M18.61,13.443H5.694c-0.238,0-0.43,0.193-0.43,0.432s0.192,0.432,0.43,0.432H18.61c0.237,0,0.431-0.193,0.431-0.432S18.848,13.443,18.61,13.443z M2.25,4.833c-0.713,0-1.292,0.578-1.292,1.292c0,0.713,0.579,1.291,1.292,1.291c0.713,0,1.292-0.578,1.292-1.291C3.542,5.412,2.963,4.833,2.25,4.833z M2.25,6.555c-0.238,0-0.43-0.191-0.43-0.43s0.192-0.431,0.43-0.431c0.238,0,0.431,0.192,0.431,0.431S2.488,6.555,2.25,6.555z"></path>
                      </svg>
                      <div>
                          <h5>Project Content</h5>
                          <br>
                          <p class="overview-text">LeapMotion gesture library; Visual Programming design and prototyping; ARKit on iPad; Voice and Gesture interactions
                          </p>
                        </div>
                </div>
              </div>
            <br>
            <p>As part of my summer internship at Apple's Applied Research Team, I initiated a research project, <b>investigating ways casual end-users could program logic for their virtual content using Reality Composer- Apple's tool for creating content in augmented reality</b>. The motivation for this is to introduce a programming environment directly in AR, so that users can avoid the tedium of jumping back and forth between their 2D programming interface and 3D AR environment, thus <b>making logic programming in 3D space more efficient and streamlined</b>.
            <br><br>
            As part of this project, I used the Apple iPad as a primary instrument for interacting in AR. I also experimented with 3D Hand Gestures using the LeapMotion Camera, which was attached to the iPad and integrated into the ARKit environment. Additionally, after several design iterations, I later integrated a voice library with the existing logic interface so users could program purely by speaking.</p>
            <br>
            <b><i>(As my work is under Apple's NDA, I am not allowed to describe the project in detail. However, my work was demoed live at internal Open House events, and videos of my work have been showcased across different teams at Apple)</i></b>
        </div>
        

        <div id="anchor-proj-design-process" class="SectionDesignProcess">
          <h4 class="ProjectSectionHeader">Design Process</h4>
        </div>

        <div id="anchor-proj-use-cases" class="SubSection">
          <h5 class="ProjectSectionHeader">Brainstorming Use Cases</h5>
          <br>
          <!-- Add an icon: 1 per design stage -->
          <p>Before examining interface designs, I drafted several possible use cases for Reality Composer, based on existing work and ideas coalesced by the rest of the Applied Research Team. For this project, we made the following assumptions about our users:
            <br>
             1. End-users have completed adding models and characters into the scene, and now would like to use logic to interact with their creations. <br>2. However, some users may come from a design-oriented background. Hence, the interface must account for the variable levels of prior programming experience end-users may have.<br>3. End users have an English-speaking background.
          </p>
        </div>

        <div id="anchor-proj-interface-design" class="SubSection">
            <h5 class="ProjectSectionHeader">Designing an Interface</h5>
            <br>
            <p>
                Examining the ideas in detail, I decided to represent the programming logic as lego blocks, where each lego block is classified based on its shape and color, and corresponds to a component of the English parts of speech, such as subjects, adjectives, and verbs. By doing so, I aimed to conceal the underlying complexity of the programming language itself, and thus make the visual interface feel more familiar and accessible, thus reducing the learning curve required to implement logic in an AR scene. Another reason was that I wanted to add voice input as a mode of interaction into our system. 
                <br><br>
                Drawing from real-world scenarios where users would interact with puzzles, legos, and blocks in real life, I decided to use a cubby as a menu, where users could reach into the cubby drawers and grab blocks out, thus generating the knowledge they wanted. The cubbies were also categorized by English parts of speech, to further abstract the underlying logical programm and thus make the logic more familiar and digestable.
                <br><br>
                The following were some existing work and projects I referenced as inspiration for this project.
            </p>
          </div>

        <div id="anchor-proj-reference" class="SubSection">
          <p>
            Scratch Programming: MIT's Scratch effectively captured a method of visualizing logic as puzzle pieces for programming. Users could easily identify and map the logical constraints of the system with the shape, color, and form of the puzzle pieces themselves, which created a layer of abstraction to conceal the programming language. One of the challenges, however, is identifying a method of mapping this 2D representation to 3D space, specifically to maximize the capabilities of 3D models to further visualize and communicate logic.
            <br><br>
            BodyMeter by KAIST: A unique way of interacting in the virtual world using a combination of voice and gestures. Although this work is specifically designed for furniture personalization, it demonstrates ways users can select, and give contextual voice input that is combined with 3D gestures to generate expressive modes of interaction.
          </p>
          </div>

        <div id="anchor-proj-use-cases" class="SubSection">
            <h5 class="ProjectSectionHeader">Adding Gesture Input</h5>
            <br>
            <p>
              Consistent with our analogy of <i>programming logic using legos</i>, I decided to use hand gestures as a primary method of input for interacting with lego blocks. To do so, I helped create a customized library for the LeapMotion cameras to identify a finite set of 3D hand gestures for users to interact with the blocks using their hands.
              <br><br>
              Combining this with the ARKit environment on the iPad, I designed a system to both create blocks and also generate a visual representation of the logic by bringing <i>logically sound</i> blocks together, as defined during the design process.
            </p>
          </div>

        <div id="anchor-proj-use-cases" class="SubSection">
            <h5 class="ProjectSectionHeader">Adding Voice Input</h5>
            <br>
            <p>
              One limitation of the gesture-based interface is the need to be precise when moving blocks around, in order to correctly attach them to the right location. To account for this, I utilized the English-based representation of our logic by adding a method of generating blocks using voice input. With help from my coworkers, I integrated a customized voice library that parsed English sentences into lego blocks, each adhering to the logical constraints of our system.
              <br><br>
              In combination with hand gestures, I also added contextual modes of input involving both gestures and voice. Users could select a virtual object in the scene using hand gestures, and generate logic for it with voice without explicitly referencing the name of the object. The combination of both modes of input enabled more expressive and contextual methods of generating logic.
            </p>
          </div>

        <div id="anchor-proj-use-cases" class="SubSection">
            <h5 class="ProjectSectionHeader">Attaching Logic to Objects in the Scene</h5>
            <br>
            <p>
              Due to the variable size and scale of the virtual environment, it may be difficult to directly attach logic into the virtual objects in the scene, as users may be limited by the physical constraints of their surroundings. Hence, in addition to the lego block interface, I also designed a virtual Apple Watch interface that was attached to the users's virtual hands, and enabled users to select, modify, and add logic to virtual characters and objects while standing in one location. 
              <br><br>
              This interface not only reduced the need to move around the scene, but it also offered a centralized workstation that follows the users, so they can conveniently modify and 'code' in their work environment.
            </p>
          </div>

        <div id="anchor-proj-design-process" class="SectionDesignProcess">
            <h4 class="ProjectSectionHeader">Testing and Evaluation</h4>
            <br>
            <p>
              After finishing the prototype, I started running informal user studies asking people within the team with and without AR experience to use the system and perform some programming tasks. Although users did praise the intuitiveness, immersiveness, and accessibility of the interface, when analyzing the data, I identified the following areas necessary for future improvement.
            </p>
        </div>

        <div id="anchor-proj-use-cases" class="SubSection">
          <h5 class="ProjectSectionHeader">Limitations to Gesture-Based Interface</h5>
          <br>
          <p>
            One challenge that users pointed out was the physical exertion required to generate large, complex logical programs. Particularly with a constrained physical environment, end users would find challenges navigating the scene to obtain and combine logical blocks together. In future, it would be helpful to consider methods of selecting and interacting with logic in a stationary position.
          </p>
        </div>

        <div id="anchor-proj-use-cases" class="SubSection">
            <h5 class="ProjectSectionHeader">Voice Input Scalability Challenges</h5>
            <br>
            <p>
              Due in part to the complexity of the English language, compounded by the limitations of our voice library, the interface is unable to generate complex logical statements purely using voice input. Additionally, when considering the population of non-English speakers, the scalability of our interface is limited, as the logical constraints of this visual interface does not translate to all other possible languages due to different semantic and syntactic nuances. 
              <br><br>
              In order to create a fully voice-based programming interface, it is necessary to precisely define the scope of the project, and identify a simpler, uniform method of representing logic using voice.
            </p>
          </div>

        <div id="anchor-proj-use-cases" class="SubSection">
            <h5 class="ProjectSectionHeader">Learning Curve</h5>
            <br>
            <p>
              Although the interface enables users to program logic into their scene much quicker, and it reduces the time taken to learn how to program logic, there are a lack of presets or guides within the current interface for novice end-users to learn through experimentation how to program in AR. As a result, it would be useful to offer visual guides that aid end-users when combining logic, and also to define presets for common logical statements users would want to generate.
            </p>
          </div>

        <div id="anchor-proj-design-process" class="SectionDesignProcess">
            <h4 class="ProjectSectionHeader">Final Thoughts</h4>
            <br>
            <p>
              As my first, self-initiated research project at Apple, I found this experience very rewarding and insightful. Not only did I gain first-hand experience in multiple stages of the design and research process, but I also received knowledgeable feedback that helped me look at visual programming in 3D space differently. Taking this learning experience with me, I continued into the remaining weeks of my internship by co-leading a research project further investigating voice as an input for programming in Reality Composer.
            </p>
        </div>
        
    </div>
  </div>
  <script src="./../JS/TweenMax.min.js" type="text/javascript"></script>
  <script src="./../JS/animationProject.js" type="text/javascript"></script>
    <script type="text/javascript">// Select all links with hashes
      $('a[href*="#"]')
        // Remove links that don't actually link to anything
        .not('[href="#"]')
        .not('[href="#0"]')
        .click(function(event) {
          // On-page links
          if (
            location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') 
            && 
            location.hostname == this.hostname
          ) {
            // Figure out element to scroll to
            var target = $(this.hash);
            target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
            // Does a scroll target exist?
            if (target.length) {
              // Only prevent default if animation is actually gonna happen
              event.preventDefault();
              $('html, body').animate({
                scrollTop: target.offset().top
              }, 1000, function() {
                // Callback after animation
                // Must change focus!
                var $target = $(target);
                $target.focus();
                if ($target.is(":focus")) { // Checking if the target was focused
                  return false;
                } else {
                  $target.attr('tabindex','-1'); // Adding tabindex for elements not focusable
                  $target.focus(); // Set focus again
                };
              });
            }
          }
        });</script>
</body>